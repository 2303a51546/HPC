{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51546/HPC/blob/main/Copy_of_Assignment_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Vector Addition (Scalar vs SIMD-like)"
      ],
      "metadata": {
        "id": "JE-aOxnXGzl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz38WBVjDMu1",
        "outputId": "aef36d97-12f2-4391-cc34-a39783616c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal loop time: 7.748841762542725\n",
            "Vectorized time: 0.04339742660522461\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "\n",
        "A = np.arange(N, dtype=np.float64)\n",
        "B = np.arange(N, dtype=np.float64)\n",
        "\n",
        "# Scalar loop\n",
        "C = np.zeros(N)\n",
        "start = time.time()\n",
        "for i in range(N):\n",
        "    C[i] = A[i] + B[i]\n",
        "end = time.time()\n",
        "print(\"Normal loop time:\", end - start)\n",
        "\n",
        "# Vectorized (SIMD-like)\n",
        "start = time.time()\n",
        "C = A + B\n",
        "end = time.time()\n",
        "print(\"Vectorized time:\", end - start)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** â€“ Observations**\n",
        "\n",
        "Scalar loop execution time is very high for large data sizes.\n",
        "\n",
        "Vectorized NumPy operation runs significantly faster.\n",
        "\n",
        "SIMD allows multiple data elements to be processed simultaneously.\n",
        "\n",
        "Python loop overhead causes poor performance in scalar method.\n",
        "\n",
        "Vectorization improves CPU utilization and efficiency."
      ],
      "metadata": {
        "id": "OdnJI5BMZm6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Reduction (Sum)"
      ],
      "metadata": {
        "id": "wGo1GUDiG43N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "A = np.ones(N, dtype=np.float64)\n",
        "\n",
        "# Normal loop\n",
        "start = time.time()\n",
        "s = 0.0\n",
        "for i in range(N):\n",
        "    s += A[i]\n",
        "end = time.time()\n",
        "print(\"Normal sum:\", s, \"Time:\", end - start)\n",
        "\n",
        "# Vectorized reduction\n",
        "start = time.time()\n",
        "s = np.sum(A)\n",
        "end = time.time()\n",
        "print(\"Vectorized sum:\", s, \"Time:\", end - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTfqsXarDh8r",
        "outputId": "32d3fc70-981f-4a72-c9bc-59a05b2a213f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal sum: 10000000.0 Time: 2.739647388458252\n",
            "Vectorized sum: 10000000.0 Time: 0.008611440658569336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Normal loop summation takes more time due to iteration overhead.\n",
        "\n",
        "Vectorized np.sum() completes the task extremely fast.\n",
        "\n",
        "SIMD instructions are used internally during reduction.\n",
        "\n",
        "Both methods give the same correct result.\n",
        "\n",
        "Vectorized reduction is preferred in high-performance computing."
      ],
      "metadata": {
        "id": "g9o4SDKpZsOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Memory Alignment Effect"
      ],
      "metadata": {
        "id": "u7J3IzA-G737"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "\n",
        "unaligned = np.arange(N + 1, dtype=np.float64)[1:]\n",
        "aligned = np.arange(N, dtype=np.float64)\n",
        "\n",
        "start = time.time()\n",
        "np.sum(unaligned)\n",
        "print(\"Unaligned time:\", time.time() - start)\n",
        "\n",
        "start = time.time()\n",
        "np.sum(aligned)\n",
        "print(\"Aligned time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkobRbKXDwL8",
        "outputId": "454b1009-471d-413f-a8e3-343127bf86bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unaligned time: 0.007345676422119141\n",
            "Aligned time: 0.007325649261474609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Execution time for aligned and unaligned arrays is nearly the same.\n",
        "\n",
        "Modern CPUs handle unaligned memory efficiently.\n",
        "\n",
        "NumPy internally optimizes memory access.\n",
        "\n",
        "No significant performance penalty is observed.\n",
        "\n",
        "Memory alignment impact is minimal at high-level NumPy operations."
      ],
      "metadata": {
        "id": "VryfTjkvZ1Yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Parallel + SIMD (Implicit)"
      ],
      "metadata": {
        "id": "wIBWs1XYG_Pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "A = np.arange(N, dtype=np.float64)\n",
        "\n",
        "start = time.time()\n",
        "B = A * 2.0\n",
        "print(\"Vectorized (SIMD + multithreaded) time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ruYbIHD3En",
        "outputId": "63fa0541-e1f2-478c-ca39-c6c4ba981aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized (SIMD + multithreaded) time: 0.026205778121948242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**\n",
        "Operation executes very fast without explicit parallel code.\n",
        "\n",
        "NumPy automatically uses SIMD instructions.\n",
        "\n",
        "Multithreading is implicitly applied where possible.\n",
        "\n",
        "Simple code achieves high performance.\n",
        "\n",
        "Demonstrates ease of parallel programming using NumPy."
      ],
      "metadata": {
        "id": "EcyshPs9aAU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Branch Divergence"
      ],
      "metadata": {
        "id": "xdOV9SnmHDXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "N = 10_000_000\n",
        "A = np.random.rand(N) * 100\n",
        "B = np.zeros(N)\n",
        "\n",
        "start = time.time()\n",
        "for i in range(N):\n",
        "    if A[i] > 50:\n",
        "        B[i] = A[i] * 2\n",
        "    else:\n",
        "        B[i] = A[i] / 2\n",
        "print(\"Branch loop time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgqvZ5A8D_4u",
        "outputId": "08293d37-9979-4925-9d9f-55d26bf3c217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch loop time: 6.7121851444244385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Execution time is very high due to conditional branching.\n",
        "\n",
        "Branch divergence slows down CPU pipelines.\n",
        "\n",
        "Each iteration checks if-else, increasing overhead.\n",
        "\n",
        "Poor SIMD utilization is observed.\n",
        "\n",
        "Not suitable for performance-critical applications."
      ],
      "metadata": {
        "id": "vAEtqMGsaZPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "B = np.where(A > 50, A * 2, A / 2)\n",
        "print(\"Vectorized conditional time:\", time.time() - start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joYjDZ7pEFLC",
        "outputId": "f863afb1-fffc-4576-c7e6-3448c4d1d7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorized conditional time: 0.1503133773803711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Vectorized conditional execution is much faster.\n",
        "\n",
        "Eliminates explicit branching inside loops.\n",
        "\n",
        "Better SIMD utilization compared to normal loop.\n",
        "\n",
        "Reduces CPU pipeline stalls.\n",
        "\n",
        "Preferred method for conditional operations on large arrays."
      ],
      "metadata": {
        "id": "TVVXdfgAaqfp"
      }
    }
  ]
}