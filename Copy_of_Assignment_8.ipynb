{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51546/HPC/blob/main/Copy_of_Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Identifying Serial Bottlenecks (Amdahl’s Law)"
      ],
      "metadata": {
        "id": "HI_UFtfpb1PO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDYX9MNZbJOI",
        "outputId": "01266357-8694-4ca7-e315-6f2416bf82a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads 1: Time = 1.0142476558685303\n",
            "Threads 2: Time = 1.3787193298339844\n",
            "Threads 4: Time = 2.3396224975585938\n",
            "Threads 8: Time = 2.4009130001068115\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "def serial_part():\n",
        "    s = 0\n",
        "    for i in range(10_000_000):\n",
        "        s += i\n",
        "    return s\n",
        "\n",
        "def parallel_part(n):\n",
        "    s = 0\n",
        "    for i in range(n):\n",
        "        s += i\n",
        "    return s\n",
        "\n",
        "def run(threads):\n",
        "    start = time.time()\n",
        "\n",
        "    # Serial region\n",
        "    serial_part()\n",
        "\n",
        "    # Parallel region\n",
        "    with Pool(threads) as p:\n",
        "        p.map(parallel_part, [2_500_000]*threads)\n",
        "\n",
        "    return time.time() - start\n",
        "\n",
        "for t in [1, 2, 4, 8]:\n",
        "    print(f\"Threads {t}: Time =\", run(t))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Execution time does not reduce proportionally with threads.\n",
        "\n",
        "Serial part dominates total runtime.\n",
        "\n",
        "Increasing threads gives diminishing returns.\n",
        "\n",
        "Speedup is limited due to serial region.\n",
        "\n",
        "Demonstrates Amdahl’s Law in practice."
      ],
      "metadata": {
        "id": "gRpGTtCfcV4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Hotspot Detection Using Timing Analysis"
      ],
      "metadata": {
        "id": "griqBv7Tcant"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def initialization():\n",
        "    time.sleep(0.5)\n",
        "\n",
        "def computation():\n",
        "    s = 0\n",
        "    for i in range(20_000_000):\n",
        "        s += i\n",
        "\n",
        "def io_task():\n",
        "    time.sleep(0.2)\n",
        "\n",
        "start = time.time()\n",
        "initialization()\n",
        "print(\"Initialization time:\", time.time() - start)\n",
        "\n",
        "start = time.time()\n",
        "computation()\n",
        "print(\"Computation time:\", time.time() - start)\n",
        "\n",
        "start = time.time()\n",
        "io_task()\n",
        "print(\"I/O time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvjegMT9ce6P",
        "outputId": "831868a5-49e5-4c73-c237-e1b5163b8a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialization time: 0.5005333423614502\n",
            "Computation time: 2.1269285678863525\n",
            "I/O time: 0.20044851303100586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Computation loop consumes maximum execution time.\n",
        "\n",
        "Initialization and I/O take significantly less time.\n",
        "\n",
        "Computation section is identified as the hotspot.\n",
        "\n",
        "Only hotspot should be optimized or parallelized.\n",
        "\n",
        "Avoids unnecessary parallelization of minor sections."
      ],
      "metadata": {
        "id": "CUiIN3aHci8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Load Imbalance Detection"
      ],
      "metadata": {
        "id": "3kl3Ma26cnlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def work(n):\n",
        "    start = time.time()\n",
        "    s = 0\n",
        "    for i in range(n):\n",
        "        s += i\n",
        "    return time.time() - start\n",
        "\n",
        "tasks = [5_000_000, 20_000_000, 5_000_000, 20_000_000]\n",
        "\n",
        "with Pool(4) as p:\n",
        "    times = p.map(work, tasks)\n",
        "\n",
        "for i, t in enumerate(times):\n",
        "    print(f\"Thread {i} time:\", t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYLeS2V1crk3",
        "outputId": "3fd153e0-901a-41c5-bf12-eafab6ea11bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 time: 1.0866992473602295\n",
            "Thread 1 time: 2.9837353229522705\n",
            "Thread 2 time: 1.2912120819091797\n",
            "Thread 3 time: 2.9934637546539307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Different threads take different execution times.\n",
        "\n",
        "Workload is unevenly distributed.\n",
        "\n",
        "Some threads finish early and remain idle.\n",
        "\n",
        "Load imbalance reduces overall performance.\n",
        "\n",
        "Dynamic scheduling can reduce imbalance."
      ],
      "metadata": {
        "id": "5ymOEv0gcwH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.False Sharing & Memory Bottlenecks (Conceptual)"
      ],
      "metadata": {
        "id": "KLQBq01Cc1oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from multiprocessing import Process, Array\n",
        "\n",
        "def update(arr, idx):\n",
        "    for _ in range(5_000_000):\n",
        "        arr[idx] += 1\n",
        "\n",
        "arr = Array('i', 4)\n",
        "\n",
        "start = time.time()\n",
        "processes = []\n",
        "for i in range(4):\n",
        "    p = Process(target=update, args=(arr, i))\n",
        "    processes.append(p)\n",
        "    p.start()\n",
        "\n",
        "for p in processes:\n",
        "    p.join()\n",
        "\n",
        "print(\"Execution time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6LxzsnIcvfE",
        "outputId": "0cbff732-d0de-473a-a1da-41198547ef65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 51.00672197341919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Multiple processes update adjacent memory locations.\n",
        "\n",
        "Performance is slower than expected.\n",
        "\n",
        "Cache contention occurs due to shared memory.\n",
        "\n",
        "Similar to false sharing in OpenMP.\n",
        "\n",
        "Padding or private data reduces memory bottlenecks."
      ],
      "metadata": {
        "id": "jN2rzhnNc9D3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Synchronization Overhead Analysis"
      ],
      "metadata": {
        "id": "XPPf4ZVGdDMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from multiprocessing import Process, Lock\n",
        "\n",
        "lock = Lock()\n",
        "counter = 0\n",
        "\n",
        "def critical_section():\n",
        "    global counter\n",
        "    for _ in range(1_000_000):\n",
        "        with lock:\n",
        "            counter += 1\n",
        "\n",
        "start = time.time()\n",
        "processes = []\n",
        "\n",
        "for _ in range(4):\n",
        "    p = Process(target=critical_section)\n",
        "    processes.append(p)\n",
        "    p.start()\n",
        "\n",
        "for p in processes:\n",
        "    p.join()\n",
        "\n",
        "print(\"Execution time:\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR-RljCTc8lp",
        "outputId": "232d3295-7d31-4363-d20b-17d1138aa4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 3.261547327041626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "Excessive locking increases execution time.\n",
        "\n",
        "Threads spend time waiting at synchronization points.\n",
        "\n",
        "Critical sections reduce parallel efficiency.\n",
        "\n",
        "Synchronization overhead dominates computation.\n",
        "\n",
        "Reduction-based approaches improve performance."
      ],
      "metadata": {
        "id": "AFMRILc5dPdS"
      }
    }
  ]
}